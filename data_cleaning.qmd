---
title: "Final Project"
author: "Clarice Tee, Eddie Andujar, Prashanthi Subbiah"
date: Nov 23, 2024
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---
```{python}
import pyarrow
import pandas as pd
import numpy as np
import os
```

Loading Data
```{python}
# Step 1: Load the datasets
energy_insecurity_df = pd.read_excel(r"C:\Users\clari\OneDrive\Documents\Python II\final_project\HC 11.1.xlsx")
solar_pv_df = pd.read_csv(r"C:\Users\clari\OneDrive\Documents\Python II\final_project\uspvdbCSV\uspvdb_v2_0_20240801.csv")

output_dir = r'C:\Users\clari\OneDrive\Documents\Python II\final_project'
```


```{python}
# Step 2: Clean and prepare the PV dataset
columns_to_keep = ['case_id', 'p_state', 'ylat', 'xlong', 'p_year', 'p_cap_ac', 'p_cap_dc']
pv_clean = solar_pv_df[columns_to_keep].copy()

# Step 3: Create dictionaries mapping states to regions and divisions
state_to_region = {
    'CT': 'Northeast', 'ME': 'Northeast', 'MA': 'Northeast', 'NH': 'Northeast', 'RI': 'Northeast', 'VT': 'Northeast',
    'NJ': 'Northeast', 'NY': 'Northeast', 'PA': 'Northeast',
    'IL': 'Midwest', 'IN': 'Midwest', 'MI': 'Midwest', 'OH': 'Midwest', 'WI': 'Midwest',
    'IA': 'Midwest', 'KS': 'Midwest', 'MN': 'Midwest', 'MO': 'Midwest', 'NE': 'Midwest', 'ND': 'Midwest', 'SD': 'Midwest',
    'DE': 'South', 'FL': 'South', 'GA': 'South', 'MD': 'South', 'NC': 'South', 'SC': 'South', 'VA': 'South', 'WV': 'South', 'DC': 'South',
    'AL': 'South', 'KY': 'South', 'MS': 'South', 'TN': 'South',
    'AR': 'South', 'LA': 'South', 'OK': 'South', 'TX': 'South',
    'AZ': 'West', 'CO': 'West', 'ID': 'West', 'MT': 'West', 'NV': 'West', 'NM': 'West', 'UT': 'West', 'WY': 'West',
    'AK': 'West', 'CA': 'West', 'HI': 'West', 'OR': 'West', 'WA': 'West'
}

state_to_division = {
    'CT': 'New England', 'ME': 'New England', 'MA': 'New England', 'NH': 'New England', 'RI': 'New England', 'VT': 'New England',
    'NJ': 'Middle Atlantic', 'NY': 'Middle Atlantic', 'PA': 'Middle Atlantic',
    'IL': 'East North Central', 'IN': 'East North Central', 'MI': 'East North Central', 'OH': 'East North Central', 'WI': 'East North Central',
    'IA': 'West North Central', 'KS': 'West North Central', 'MN': 'West North Central', 'MO': 'West North Central',
    'NE': 'West North Central', 'ND': 'West North Central', 'SD': 'West North Central',
    'DE': 'South Atlantic', 'FL': 'South Atlantic', 'GA': 'South Atlantic', 'MD': 'South Atlantic', 'NC': 'South Atlantic',
    'SC': 'South Atlantic', 'VA': 'South Atlantic', 'WV': 'South Atlantic', 'DC': 'South Atlantic',
    'AL': 'East South Central', 'KY': 'East South Central', 'MS': 'East South Central', 'TN': 'East South Central',
    'AR': 'West South Central', 'LA': 'West South Central', 'OK': 'West South Central', 'TX': 'West South Central',
    'AZ': 'Mountain', 'CO': 'Mountain', 'ID': 'Mountain', 'MT': 'Mountain', 'NV': 'Mountain', 'NM': 'Mountain', 'UT': 'Mountain', 'WY': 'Mountain',
    'AK': 'Pacific', 'CA': 'Pacific', 'HI': 'Pacific', 'OR': 'Pacific', 'WA': 'Pacific'
}

# Step 4: Add region and division columns to the PV dataset
pv_clean['region'] = pv_clean['p_state'].map(state_to_region)
pv_clean['division'] = pv_clean['p_state'].map(state_to_division)

```
```{python}

# Step 5: Aggregate PV data by region and division
pv_agg_region = pv_clean.groupby('region').agg({
    'case_id': 'count',
    'p_cap_ac': 'sum',
    'p_cap_dc': 'sum'
}).reset_index()

pv_agg_division = pv_clean.groupby('division').agg({
    'case_id': 'count',
    'p_cap_ac': 'sum',
    'p_cap_dc': 'sum'
}).reset_index()

# Step 6: Rename columns for clarity
pv_agg_region = pv_agg_region.rename(columns={
    'case_id': 'facility_count',
    'p_cap_ac': 'total_cap_ac',
    'p_cap_dc': 'total_cap_dc'
})

pv_agg_division = pv_agg_division.rename(columns={
    'case_id': 'facility_count',
    'p_cap_ac': 'total_cap_ac',
    'p_cap_dc': 'total_cap_dc'
})

# Step 7: Save the results
pv_clean.to_csv(os.path.join(output_dir, 'pv_data_regions_divisions.csv'), index=False)
pv_agg_region.to_csv(os.path.join(output_dir, 'pv_data_aggregated_by_region.csv'), index=False)
pv_agg_division.to_csv(os.path.join(output_dir, 'pv_data_aggregated_by_division.csv'), index=False)

print(f"Data processing complete. Check the output CSV files in {output_dir}")
```


```{python}
# Print the column names to verify the structure
print("Columns in the energy insecurity dataset:")
print(energy_insecurity_df.columns)

# First, let's create new region and division columns
energy_insecurity_df['region'] = None
energy_insecurity_df['division'] = None

# Map the regions and divisions based on the actual data structure
regions = ['Northeast', 'Midwest', 'South', 'West']
for idx, row in energy_insecurity_df.iterrows():
    # Use the first column name since it contains the region/division information
    location = row.iloc[0]  # Get the first column value
    if pd.notna(location):  # Check if the value is not NaN
        if location in regions:
            energy_insecurity_df.at[idx, 'region'] = location
        else:
            # Find the parent region for each division
            if location.strip() in ['New England', 'Middle Atlantic']:
                energy_insecurity_df.at[idx, 'region'] = 'Northeast'
            elif location.strip() in ['East North Central', 'West North Central']:
                energy_insecurity_df.at[idx, 'region'] = 'Midwest'
            elif location.strip() in ['South Atlantic', 'East South Central', 'West South Central']:
                energy_insecurity_df.at[idx, 'region'] = 'South'
            elif location.strip() in ['Mountain', 'Pacific', 'Mountain North', 'Mountain South']:
                energy_insecurity_df.at[idx, 'region'] = 'West'
            energy_insecurity_df.at[idx, 'division'] = location.strip()

# Merge Mountain North and South into Mountain
energy_insecurity_df['division'] = energy_insecurity_df['division'].replace({
    'Mountain North': 'Mountain',
    'Mountain South': 'Mountain'
})

# Save the cleaned data
output_file = os.path.join(output_dir, "HC_11.1_cleaned.xlsx")
energy_insecurity_df.to_excel(output_file, index=False)
print(f"Cleaned energy insecurity data saved to {output_file}")

# Print unique values to verify the cleaning
print("\nUnique regions after cleaning:")
print(energy_insecurity_df['region'].unique())
print("\nUnique divisions after cleaning:")
print(energy_insecurity_df['division'].unique())
    
```

Now, we want to merge the two datasets

```{python}

```